# -*- coding: utf-8 -*-
"""
Created on Sun Dec 28 17:08:57 2025

@author: sasha
"""

import requests
from bs4 import BeautifulSoup
import random

# ==========================================
# 1. çˆ¬ç¾é£Ÿ (æ„›é£Ÿè¨˜ iFoodie)
# ==========================================
def scrape_ifoodie(location, keyword):
    print(f"ğŸ•·ï¸ [ç¾é£Ÿæ¨¡å¼] æ­£åœ¨çˆ¬å–ï¼š{location} çš„ {keyword} ...")
    url = f"https://ifoodie.tw/explore/{location}/list/{keyword}"
    headers = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" }

    try:
        response = requests.get(url, headers=headers, timeout=5)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "html.parser")
            items = soup.find_all("div", class_="restaurant-item", limit=5)
            results = []
            for item in items:
                try:
                    title = item.find("a", class_="title-text").text.strip()
                    img_tag = item.find("img", class_="lazy-load")
                    image = img_tag["data-src"] if img_tag and "data-src" in img_tag.attrs else "https://images.unsplash.com/photo-1504674900247-0877df9cc836"
                    rating = item.find("div", class_="text").text.strip() if item.find("div", class_="text") else "4.0"
                    address = item.find("div", class_="address-row").text.strip() if item.find("div", class_="address-row") else "åœ°å€è©³è¦‹é€£çµ"
                    link = "https://ifoodie.tw" + item.find("a", class_="title-text")["href"]
                    
                    results.append({ "name": title, "score": rating, "image": image, "address": address, "link": link })
                except: continue
            
            if results: return results
    except Exception as e:
        print(f"âŒ ç¾é£Ÿçˆ¬èŸ²éŒ¯èª¤: {e}")
    
    return [] # å¤±æ•—å›å‚³ç©ºé™£åˆ—

# ==========================================
# 2. çˆ¬æ™¯é» (æ—…éŠç‹ TravelKing)
# ==========================================
def scrape_travelking(keyword):
    print(f"ğŸ•·ï¸ [æ™¯é»æ¨¡å¼] æ­£åœ¨çˆ¬å–ï¼š{keyword} ...")
    # æ—…éŠç‹çš„æœå°‹ç¶²å€çµæ§‹
    url = f"https://www.travelking.com.tw/tourguide/search/qw.asp?q={keyword}"
    headers = { "User-Agent": "Mozilla/5.0" }

    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.encoding = 'utf-8' # å¼·åˆ¶ç·¨ç¢¼ï¼Œé¿å…äº‚ç¢¼
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "html.parser")
            # æŠ“å–æœå°‹çµæœåˆ—è¡¨
            box = soup.find("div", class_="box_search")
            if box:
                items = box.find_all("li", limit=5)
                results = []
                for item in items:
                    try:
                        # æŠ“æ¨™é¡Œèˆ‡é€£çµ
                        h4 = item.find("h4")
                        if not h4: continue
                        a_tag = h4.find("a")
                        title = a_tag.text.strip()
                        link = a_tag["href"]
                        
                        # æŠ“ç°¡ä»‹ (ä½œç‚ºåœ°å€æˆ–æè¿°é¡¯ç¤º)
                        desc = item.find("div", class_="text").text.strip()[:30] + "..." if item.find("div", class_="text") else "ç†±é–€æ™¯é»"
                        
                        # æŠ“åœ–ç‰‡ (æ—…éŠç‹æœå°‹é æœ‰æ™‚æ²’åœ–ï¼Œæˆ‘å€‘ç”¨éš¨æ©Ÿé¢¨æ™¯åœ–å–ä»£ï¼Œè®“å¡ç‰‡å¥½çœ‹)
                        image = "https://images.unsplash.com/photo-1469854523086-cc02fe5d8800" 

                        # å˜—è©¦æŠ“å–çœŸå¯¦åœ–ç‰‡ (å¦‚æœæœ‰)
                        img_tag = item.find("img")
                        if img_tag and "src" in img_tag.attrs:
                            image = img_tag["src"]

                        results.append({
                            "name": title,
                            "score": "æ¨è–¦", # æ™¯é»é€šå¸¸æ²’è©•åˆ†ï¼Œæ”¹é¡¯ç¤ºæ–‡å­—
                            "image": image,
                            "address": desc, # é€™è£¡æ”¹æ”¾ç°¡ä»‹
                            "link": link
                        })
                    except: continue
                
                if results: return results
    except Exception as e:
        print(f"âŒ æ™¯é»çˆ¬èŸ²éŒ¯èª¤: {e}")

    # ==========================================
    # 3. å‚™æ´è³‡æ–™ (å¦‚æœå…©å€‹éƒ½æ›æ‰)
    # ==========================================
    return [
        {
            "name": f"æœå°‹å¤±æ•—: {keyword}",
            "score": "N/A",
            "image": "https://images.unsplash.com/photo-1594322436404-5a0526db4d13",
            "address": "ç³»çµ±å¿™ç·šä¸­æˆ–æ‰¾ä¸åˆ°è³‡æ–™ï¼Œè«‹ç¨å¾Œå†è©¦",
            "link": "https://www.google.com/maps"
        }
    ]